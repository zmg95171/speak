# 实时语音交互部署指南 (Real-time Voice Interaction Deployment Guide)

本指南详细说明了 FluentScene 项目如何集成 Google Gemini Multimodal Live API 实现低延迟、类真人的实时语音对话功能。

## 1. 技术架构概述

本项目采用**WebSocket**双向流式通信，直接与 Google Gemini 服务器建立连接。

*   **前端框架**: React + Vite + TypeScript
*   **AI SDK**: `@google/genai` (Google Generic AI SDK for Web)
*   **通信协议**: WebSocket (通过 SDK 封装)
*   **音频处理**:
    *   **输入**: Web Audio API (`AudioWorklet`) 采集麦克风原始 PCM 数据。
    *   **输出**: Web Audio API (`AudioContext`) 播放服务器返回的 PCM 音频流。

---

## 2. 环境配置 (Environment Setup)

### 2.1 获取 API Key
1.  访问 [Google AI Studio](https://aistudio.google.com/)。
2.  创建一个新的 API Key。
3.  **注意**: 确保该 Key 关联的项目已启用 **Generative Language API**。

### 2.2 配置环境变量
在项目根目录创建或编辑 `.env.local` 文件：

```env
# 你的 Google Gemini API Key
SERVER_GEMINI_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

### 2.3 Vite 配置 (`vite.config.ts`)
为了确保 API Key 能在前端代码中安全读取（仅限开发环境或受控环境），我们在 Vite 配置中进行了映射：

```typescript
export default defineConfig(({ mode }) => {
  const env = loadEnv(mode, '.', '');
  return {
    define: {
      // 优先使用 SERVER_GEMINI_API_KEY，兼容 GEMINI_API_KEY
      'process.env.API_KEY': JSON.stringify(env.SERVER_GEMINI_API_KEY || env.GEMINI_API_KEY),
    }
  };
});
```

---

## 3. 核心代码实现

实时交互的核心逻辑位于 `components/LiveSession.tsx`。

### 3.1 初始化连接
使用 `GoogleGenAI` 客户端建立 Live Session 连接。

```typescript
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

const sessionPromise = ai.live.connect({
  // 关键：必须使用支持 bidiGenerateContent 的模型
  // 推荐: gemini-2.5-flash-native-audio-preview-12-2025 或 gemini-2.0-flash-exp
  model: 'gemini-2.5-flash-native-audio-preview-12-2025',
  config: {
    responseModalities: [Modality.AUDIO], // 指定响应为音频
    systemInstruction: { parts: [{ text: scenario.systemInstruction }] }, // 注入提示词
    speechConfig: {
      voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Puck' } }, // 设置音色 (Puck, Charon, Fenrir 等)
    },
  },
  callbacks: {
    onopen: () => { ... },    // 连接成功
    onmessage: () => { ... }, // 接收音频/文本
    onclose: () => { ... },   // 连接关闭
    onerror: () => { ... }    // 错误处理
  }
});
```

### 3.2 音频采集 (Audio Input)
为了避免主线程阻塞并提高性能，我们使用 **`AudioWorklet`** 替代过时的 `ScriptProcessorNode`。

1.  **加载 Worklet**: 动态创建一个处理音频缓冲区的处理器。
2.  **缓冲策略**: 每收集约 4096 个采样点（约 256ms）发送一次数据包，以减少 WebSocket 通信频率，保持连接稳定。
3.  **发送数据**: 调用 `session.sendRealtimeInput` 发送 PCM 数据。

```typescript
// Worklet 伪代码逻辑
class AudioInputProcessor extends AudioWorkletProcessor {
  process(inputs) {
    // 收集音频数据并发送到主线程
    this.port.postMessage(inputBuffer); 
    return true;
  }
}
```

### 3.3 音频播放 (Audio Output)
接收到服务器返回的 `serverContent.modelTurn` 后，包含 Base64 编码的 PCM 音频：

1.  **解码**: 将 Base64 转为 `Float32Array`。
2.  **播放**: 使用 `AudioContext.createBufferSource()` 创建音频源并播放。
3.  **同步**: 维护 `nextStartTime` 时间戳，确保音频片段无缝衔接播放，不会重叠或断档。

### 3.4 打断功能 (Interruption)
当用户说话时，如果模型正在说话，服务器会发送 `interrupted` 信号。
前端接收到此信号后，必须立即调用 `source.stop()` 停止当前播放的音频，实现自然的“抢话”效果。

---

---

## 5. Vercel 部署指南 (Vercel Deployment)

为了将本项目发布到 Vercel，建议使用 **GitHub 关联部署** 方案，以便于后续的自动更新。

### 5.1 步骤 1：Push 到 GitHub
1.  在 GitHub 上创建一个新的私有仓库。
2.  将本地代码推送到该仓库：
    ```bash
    git add .
    git commit -m "Initial commit for Vercel deployment"
    git branch -M main
    git remote add origin https://github.com/zmg95171/speak.git
    git push -u origin main
    ```

### 5.2 步骤 2：在 Vercel 导入项目
1.  登录 [Vercel 控制台](https://vercel.com/)。
2.  点击 **"Add New" -> "Project"**。
3.  从 GitHub 导入刚才创建的仓库。

### 5.3 步骤 3：配置环境变量 (重要)
在部署设置界面，展开 **"Environment Variables"** 部分，添加以下变量：
*   **Key**: `GEMINI_API_KEY`
*   **Value**: *你的 Google Gemini API Key*
*   **Key**: `SUPABASE_URL`
*   **Value**: `https://cywiodjwjlisjbkhzxnm.supabase.co`
*   **Key**: `SUPABASE_ANON_KEY`
*   **Value**: `sb_publishable_Nq38I056pSAcIH6hd6FP1g_GkBk3G6r`

### 5.4 步骤 4：部署与访问
1.  点击 **"Deploy"**。
2.  等待构建完成。Vercel 会自动识别这是一个 Vite 项目并完成打包。
3.  部署完成后，你将获得一个 `https://your-project.vercel.app` 的访问地址。

---

## 6. 注意事项

1.  **安全隐患**: 由于本项目是纯前端应用，打包后的 API Key 会存在于 JS 资源中。**建议在 AI Studio 中为该 Key 设置来源域名限制（Referrer Restriction）**，仅允许你自己的 Vercel 域名访问。
2.  **网络延迟**: Vercel 的部署服务器通常在海外，直接与 Google Gemini 服务器通信速度较快，但在国内访问 Vercel 域名可能需要稳定的网络环境。
3.  **模型一致性**: 确保已根据 `Live API待修复.md` 中的建议，统一锁定了 `gemini-2.5-flash-native-audio-preview-12-2025` 模型。

## 7.版本控制

1. 什么是版本控制 (Git)？
在你的项目中，Git 就像是一个“存档点”管理器。每次你完成一个功能修复（比如这次），你就创建一个存档（Commit），然后把它上传（Push）到 GitHub。
2. 自动化流程
当你执行 git push 时，发生的链路如下：
• 本地 -> GitHub (代码仓库) -> Vercel (监控到新代码) -> 自动重新构建并上线。
￼
现在请执行以下命令来发布修复：
请在你的终端（PowerShell）中依次输入：
bash
￼
￼
# 1. 将刚才的修改加入“待存档区”
git add .
￼
# 2. 创建一个名为“修复Vercel环境变量读取”的存档
git commit -m "Fix: correct env variable detection and session fallback for Vercel"
￼
# 3. 推送到 GitHub
# 这将自动触发 Vercel 的重新部署
git push origin main
执行完后：
1. 前往 Vercel 仪表盘。
2. 你会看到一个新的 Deployment 正在进行中。
3. 部署完成后，刷新网页测试。如果还是不通过，请尝试在浏览器中清理一次 LocalStorage 或者使用无痕模式（因为我们刚才修改了存储逻辑，需要让它重新加载一次）。
